"""
ì²­ë…„ ì •ì±… ì¶”ì²œ ì‹œìŠ¤í…œ - ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ
MongoDB ì¸ë±ìŠ¤ ê´€ë¦¬, ìºì‹±, ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ì œê³µ
"""

import time
import json
import hashlib
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Callable, Union
from functools import wraps
from collections import defaultdict, OrderedDict
import threading
import asyncio

from pymongo import MongoClient, ASCENDING, DESCENDING, TEXT
from pymongo.errors import OperationFailure
from .logging import get_logger, get_database_logger

logger = get_logger("performance")
db_logger = get_database_logger()


class LRUCache:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ LRU ìºì‹œ êµ¬í˜„"""

    def __init__(self, max_size: int = 1000, ttl: int = 3600):
        """
        LRU ìºì‹œ ì´ˆê¸°í™”

        Args:
            max_size: ìµœëŒ€ ìºì‹œ í¬ê¸°
            ttl: Time To Live (ì´ˆ)
        """
        self.max_size = max_size
        self.ttl = ttl
        self.cache = OrderedDict()
        self.timestamps = {}
        self.lock = threading.Lock()

    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        with self.lock:
            if key in self.cache:
                # TTL í™•ì¸
                if time.time() - self.timestamps[key] > self.ttl:
                    del self.cache[key]
                    del self.timestamps[key]
                    return None

                # LRU ì—…ë°ì´íŠ¸
                self.cache.move_to_end(key)
                return self.cache[key]
            return None

    def put(self, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        with self.lock:
            if key in self.cache:
                self.cache.move_to_end(key)
            else:
                if len(self.cache) >= self.max_size:
                    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                    oldest = next(iter(self.cache))
                    del self.cache[oldest]
                    del self.timestamps[oldest]

            self.cache[key] = value
            self.timestamps[key] = time.time()

    def clear(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        with self.lock:
            self.cache.clear()
            self.timestamps.clear()

    def size(self) -> int:
        """í˜„ì¬ ìºì‹œ í¬ê¸°"""
        return len(self.cache)

    def stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´"""
        with self.lock:
            current_time = time.time()
            expired_count = sum(
                1 for ts in self.timestamps.values()
                if current_time - ts > self.ttl
            )
            return {
                "size": len(self.cache),
                "max_size": self.max_size,
                "expired_items": expired_count,
                "ttl": self.ttl
            }


class CacheManager:
    """í†µí•© ìºì‹œ ê´€ë¦¬ì"""

    def __init__(self):
        self.caches = {
            "policies": LRUCache(max_size=500, ttl=3600),      # ì •ì±… ë°ì´í„°
            "profiles": LRUCache(max_size=1000, ttl=1800),     # í”„ë¡œí•„ ë°ì´í„°
            "gpt_responses": LRUCache(max_size=200, ttl=86400), # GPT ì‘ë‹µ
            "matching_results": LRUCache(max_size=500, ttl=1800) # ë§¤ì¹­ ê²°ê³¼
        }
        self.hit_count = defaultdict(int)
        self.miss_count = defaultdict(int)

    def get_cache(self, cache_name: str) -> LRUCache:
        """íŠ¹ì • ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if cache_name not in self.caches:
            self.caches[cache_name] = LRUCache()
        return self.caches[cache_name]

    def get(self, cache_name: str, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        cache = self.get_cache(cache_name)
        value = cache.get(key)

        if value is not None:
            self.hit_count[cache_name] += 1
            logger.debug(f"ìºì‹œ íˆíŠ¸: {cache_name}:{key}")
        else:
            self.miss_count[cache_name] += 1
            logger.debug(f"ìºì‹œ ë¯¸ìŠ¤: {cache_name}:{key}")

        return value

    def put(self, cache_name: str, key: str, value: Any):
        """ìºì‹œì— ê°’ ì €ì¥"""
        cache = self.get_cache(cache_name)
        cache.put(key, value)
        logger.debug(f"ìºì‹œ ì €ì¥: {cache_name}:{key}")

    def invalidate(self, cache_name: str, key: Optional[str] = None):
        """ìºì‹œ ë¬´íš¨í™”"""
        cache = self.get_cache(cache_name)
        if key is None:
            cache.clear()
            logger.info(f"ìºì‹œ ì „ì²´ ì‚­ì œ: {cache_name}")
        else:
            if key in cache.cache:
                del cache.cache[key]
                del cache.timestamps[key]
                logger.info(f"ìºì‹œ ì‚­ì œ: {cache_name}:{key}")

    def get_stats(self) -> Dict[str, Any]:
        """ì „ì²´ ìºì‹œ í†µê³„"""
        stats = {}
        for cache_name, cache in self.caches.items():
            cache_stats = cache.stats()
            cache_stats.update({
                "hits": self.hit_count[cache_name],
                "misses": self.miss_count[cache_name],
                "hit_rate": (
                    self.hit_count[cache_name] /
                    (self.hit_count[cache_name] + self.miss_count[cache_name])
                    if (self.hit_count[cache_name] + self.miss_count[cache_name]) > 0
                    else 0
                )
            })
            stats[cache_name] = cache_stats
        return stats


# ì „ì—­ ìºì‹œ ë§¤ë‹ˆì €
cache_manager = CacheManager()


def create_cache_key(*args, **kwargs) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    key_data = {"args": args, "kwargs": sorted(kwargs.items())}
    key_string = json.dumps(key_data, sort_keys=True, default=str)
    return hashlib.md5(key_string.encode()).hexdigest()


def cached(cache_name: str, ttl: Optional[int] = None):
    """ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{create_cache_key(*args, **kwargs)}"

            # ìºì‹œ ì¡°íšŒ
            result = cache_manager.get(cache_name, cache_key)
            if result is not None:
                return result

            # í•¨ìˆ˜ ì‹¤í–‰ ë° ìºì‹œ ì €ì¥
            result = func(*args, **kwargs)
            cache_manager.put(cache_name, cache_key, result)
            return result

        return wrapper
    return decorator


class MongoIndexManager:
    """MongoDB ì¸ë±ìŠ¤ ê´€ë¦¬ì"""

    def __init__(self, mongo_handler):
        """
        ì¸ë±ìŠ¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”

        Args:
            mongo_handler: MongoDBHandler ì¸ìŠ¤í„´ìŠ¤
        """
        self.mongo_handler = mongo_handler
        self.db_logger = get_database_logger()

    def create_policy_indexes(self):
        """ì •ì±… ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            policies_collection = self.mongo_handler.get_collection("policies")

            # ë³µí•© ì¸ë±ìŠ¤ë“¤
            indexes = [
                # ì¹´í…Œê³ ë¦¬ ì¸ë±ìŠ¤
                [("category", ASCENDING)],

                # ì§€ì—­ ì¸ë±ìŠ¤
                [("target_regions", ASCENDING)],

                # ì—°ë ¹ ë²”ìœ„ ì¸ë±ìŠ¤
                [("target_age_min", ASCENDING), ("target_age_max", ASCENDING)],

                # ê³ ìš© ìƒíƒœ ì¸ë±ìŠ¤
                [("target_employment", ASCENDING)],

                # ë³µí•© ê²€ìƒ‰ ì¸ë±ìŠ¤ (ì¹´í…Œê³ ë¦¬ + ì§€ì—­)
                [("category", ASCENDING), ("target_regions", ASCENDING)],

                # ë³µí•© ê²€ìƒ‰ ì¸ë±ìŠ¤ (ì¹´í…Œê³ ë¦¬ + ì—°ë ¹)
                [("category", ASCENDING), ("target_age_min", ASCENDING), ("target_age_max", ASCENDING)],

                # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤
                [("title", TEXT), ("benefit", TEXT), ("description", TEXT)],

                # ì •ë ¬ìš© ì¸ë±ìŠ¤
                [("created_at", DESCENDING)],
                [("updated_at", DESCENDING)],

                # ì •ì±… ID ê³ ìœ  ì¸ë±ìŠ¤
                [("policy_id", ASCENDING)]
            ]

            created_indexes = []
            for index_fields in indexes:
                try:
                    index_name = policies_collection.create_index(index_fields)
                    created_indexes.append(index_name)
                    self.db_logger.info(
                        f"ì •ì±… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_fields}",
                        extra_collection="policies",
                        extra_index=str(index_fields)
                    )
                except Exception as e:
                    self.db_logger.warning(
                        f"ì •ì±… ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index_fields} - {e}",
                        extra_collection="policies",
                        extra_error=str(e)
                    )

            return created_indexes

        except Exception as e:
            self.db_logger.error(f"ì •ì±… ì¸ë±ìŠ¤ ìƒì„± ì „ì²´ ì‹¤íŒ¨: {e}")
            return []

    def create_profile_indexes(self):
        """í”„ë¡œí•„ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            profiles_collection = self.mongo_handler.get_collection("user_profiles")

            indexes = [
                # í”„ë¡œí•„ ID ê³ ìœ  ì¸ë±ìŠ¤
                [("profile_id", ASCENDING)],

                # ì‚¬ìš©ì ê²€ìƒ‰ ì¸ë±ìŠ¤
                [("age", ASCENDING)],
                [("region", ASCENDING)],
                [("employment", ASCENDING)],
                [("income", ASCENDING)],

                # ë³µí•© ê²€ìƒ‰ ì¸ë±ìŠ¤
                [("age", ASCENDING), ("region", ASCENDING)],
                [("region", ASCENDING), ("employment", ASCENDING)],

                # ì‹œê°„ ì¸ë±ìŠ¤
                [("created_at", DESCENDING)],
                [("updated_at", DESCENDING)]
            ]

            created_indexes = []
            for index_fields in indexes:
                try:
                    index_name = profiles_collection.create_index(index_fields)
                    created_indexes.append(index_name)
                    self.db_logger.info(
                        f"í”„ë¡œí•„ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_fields}",
                        extra_collection="user_profiles",
                        extra_index=str(index_fields)
                    )
                except Exception as e:
                    self.db_logger.warning(
                        f"í”„ë¡œí•„ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index_fields} - {e}",
                        extra_collection="user_profiles",
                        extra_error=str(e)
                    )

            return created_indexes

        except Exception as e:
            self.db_logger.error(f"í”„ë¡œí•„ ì¸ë±ìŠ¤ ìƒì„± ì „ì²´ ì‹¤íŒ¨: {e}")
            return []

    def create_recommendation_indexes(self):
        """ì¶”ì²œ ì´ë ¥ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            recommendations_collection = self.mongo_handler.get_collection("recommendations")

            indexes = [
                # ì‚¬ìš©ìë³„ ì¶”ì²œ ì´ë ¥ ì¡°íšŒ ì¸ë±ìŠ¤
                [("user_id", ASCENDING), ("created_at", DESCENDING)],

                # ì„¸ì…˜ ID ì¸ë±ìŠ¤
                [("session_id", ASCENDING)],

                # ì‹œê°„ ê¸°ë°˜ ì¸ë±ìŠ¤
                [("created_at", DESCENDING)],

                # ì„±ëŠ¥ ë¶„ì„ìš© ì¸ë±ìŠ¤
                [("avg_score", DESCENDING)],
                [("total_recommendations", DESCENDING)]
            ]

            created_indexes = []
            for index_fields in indexes:
                try:
                    index_name = recommendations_collection.create_index(index_fields)
                    created_indexes.append(index_name)
                    self.db_logger.info(
                        f"ì¶”ì²œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_fields}",
                        extra_collection="recommendations",
                        extra_index=str(index_fields)
                    )
                except Exception as e:
                    self.db_logger.warning(
                        f"ì¶”ì²œ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index_fields} - {e}",
                        extra_collection="recommendations",
                        extra_error=str(e)
                    )

            return created_indexes

        except Exception as e:
            self.db_logger.error(f"ì¶”ì²œ ì¸ë±ìŠ¤ ìƒì„± ì „ì²´ ì‹¤íŒ¨: {e}")
            return []

    def create_all_indexes(self):
        """ëª¨ë“  ì¸ë±ìŠ¤ ìƒì„±"""
        logger.info("MongoDB ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘")
        start_time = time.time()

        results = {
            "policies": self.create_policy_indexes(),
            "profiles": self.create_profile_indexes(),
            "recommendations": self.create_recommendation_indexes()
        }

        end_time = time.time()
        duration = end_time - start_time

        total_indexes = sum(len(indexes) for indexes in results.values())
        logger.info(
            f"MongoDB ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {total_indexes}ê°œ ({duration:.3f}ì´ˆ)",
            extra_duration=duration,
            extra_total_indexes=total_indexes
        )

        return results

    def list_indexes(self, collection_name: str) -> List[Dict]:
        """ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ì¸ë±ìŠ¤ ì¡°íšŒ"""
        try:
            collection = self.mongo_handler.get_collection(collection_name)
            return list(collection.list_indexes())
        except Exception as e:
            self.db_logger.error(f"ì¸ë±ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {collection_name} - {e}")
            return []

    def drop_index(self, collection_name: str, index_name: str):
        """íŠ¹ì • ì¸ë±ìŠ¤ ì‚­ì œ"""
        try:
            collection = self.mongo_handler.get_collection(collection_name)
            collection.drop_index(index_name)
            self.db_logger.info(f"ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ: {collection_name}.{index_name}")
        except Exception as e:
            self.db_logger.error(f"ì¸ë±ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {collection_name}.{index_name} - {e}")


class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""

    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_times = {}

    def start_timer(self, operation: str) -> str:
        """íƒ€ì´ë¨¸ ì‹œì‘"""
        timer_id = f"{operation}_{int(time.time() * 1000)}"
        self.start_times[timer_id] = time.time()
        return timer_id

    def end_timer(self, timer_id: str) -> float:
        """íƒ€ì´ë¨¸ ì¢…ë£Œ ë° ì†Œìš” ì‹œê°„ ë°˜í™˜"""
        if timer_id in self.start_times:
            duration = time.time() - self.start_times[timer_id]
            del self.start_times[timer_id]
            return duration
        return 0.0

    def record_metric(self, operation: str, duration: float, **metadata):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        metric = {
            "timestamp": datetime.now(),
            "duration": duration,
            **metadata
        }
        self.metrics[operation].append(metric)

        # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
        if len(self.metrics[operation]) > 1000:
            self.metrics[operation] = self.metrics[operation][-1000:]

    def get_stats(self, operation: str = None) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
        if operation:
            if operation not in self.metrics:
                return {}

            durations = [m["duration"] for m in self.metrics[operation]]
            return {
                "operation": operation,
                "count": len(durations),
                "avg_duration": sum(durations) / len(durations),
                "min_duration": min(durations),
                "max_duration": max(durations),
                "total_duration": sum(durations)
            }
        else:
            # ì „ì²´ í†µê³„
            stats = {}
            for op, metrics in self.metrics.items():
                durations = [m["duration"] for m in metrics]
                stats[op] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations) if durations else 0,
                    "min_duration": min(durations) if durations else 0,
                    "max_duration": max(durations) if durations else 0,
                    "total_duration": sum(durations) if durations else 0
                }
            return stats

    def clear_metrics(self):
        """ëª¨ë“  ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        self.metrics.clear()
        self.start_times.clear()


# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
performance_monitor = PerformanceMonitor()


def monitor_performance(operation: str):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            timer_id = performance_monitor.start_timer(operation)
            try:
                result = func(*args, **kwargs)
                duration = performance_monitor.end_timer(timer_id)
                performance_monitor.record_metric(
                    operation,
                    duration,
                    success=True,
                    function=func.__name__
                )
                return result
            except Exception as e:
                duration = performance_monitor.end_timer(timer_id)
                performance_monitor.record_metric(
                    operation,
                    duration,
                    success=False,
                    error=str(e),
                    function=func.__name__
                )
                raise
        return wrapper
    return decorator


class DatabaseQueryOptimizer:
    """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”"""

    @staticmethod
    def optimize_policy_query(filters: Dict[str, Any]) -> Dict[str, Any]:
        """ì •ì±… ì¿¼ë¦¬ ìµœì í™”"""
        optimized_query = {}

        # ì¹´í…Œê³ ë¦¬ í•„í„°
        if "category" in filters:
            optimized_query["category"] = filters["category"]

        # ì§€ì—­ í•„í„°
        if "region" in filters:
            optimized_query["target_regions"] = {"$in": [filters["region"], "ì „êµ­"]}

        # ë‚˜ì´ í•„í„°
        if "age" in filters:
            age = filters["age"]
            optimized_query["$and"] = [
                {"target_age_min": {"$lte": age}},
                {"target_age_max": {"$gte": age}}
            ]

        # ê³ ìš© ìƒíƒœ í•„í„°
        if "employment" in filters:
            optimized_query["target_employment"] = {"$in": [filters["employment"]]}

        # ì†Œë“ í•„í„°
        if "income" in filters:
            optimized_query["$or"] = [
                {"target_income_max": {"$gte": filters["income"]}},
                {"target_income_max": None}  # ì†Œë“ ì œí•œ ì—†ìŒ
            ]

        return optimized_query

    @staticmethod
    def create_aggregation_pipeline(query: Dict, sort_field: str = None, limit: int = None) -> List[Dict]:
        """ì§‘ê³„ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        pipeline = []

        # Match ìŠ¤í…Œì´ì§€
        if query:
            pipeline.append({"$match": query})

        # Sort ìŠ¤í…Œì´ì§€
        if sort_field:
            pipeline.append({"$sort": {sort_field: -1}})

        # Limit ìŠ¤í…Œì´ì§€
        if limit:
            pipeline.append({"$limit": limit})

        # í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒ
        pipeline.append({
            "$project": {
                "_id": 0,
                "policy_id": 1,
                "title": 1,
                "category": 1,
                "target_age_min": 1,
                "target_age_max": 1,
                "target_regions": 1,
                "target_employment": 1,
                "target_income_max": 1,
                "benefit": 1,
                "budget_max": 1,
                "deadline": 1,
                "application_url": 1
            }
        })

        return pipeline


def setup_performance_optimizations(mongo_handler):
    """ì„±ëŠ¥ ìµœì í™” ì„¤ì •"""
    try:
        logger.info("ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì‹œì‘")

        # ì¸ë±ìŠ¤ ìƒì„±
        index_manager = MongoIndexManager(mongo_handler)
        index_results = index_manager.create_all_indexes()

        # ìºì‹œ ì´ˆê¸°í™”
        cache_manager.invalidate("policies")
        cache_manager.invalidate("profiles")

        logger.info(
            "ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì™„ë£Œ",
            extra_indexes_created=sum(len(indexes) for indexes in index_results.values()),
            extra_cache_initialized=True
        )

        return True

    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ìµœì í™” ì„¤ì • ì‹¤íŒ¨: {e}")
        return False


def get_performance_stats() -> Dict[str, Any]:
    """ì „ì²´ ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
    return {
        "cache_stats": cache_manager.get_stats(),
        "performance_stats": performance_monitor.get_stats(),
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    """ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ì²­ë…„ ì •ì±… ì¶”ì²œ ì‹œìŠ¤í…œ - ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")

    # ìºì‹œ í…ŒìŠ¤íŠ¸
    cache_manager.put("test", "key1", {"data": "value1"})
    cached_value = cache_manager.get("test", "key1")
    print(f"ìºì‹œ í…ŒìŠ¤íŠ¸: {cached_value}")

    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
    timer_id = performance_monitor.start_timer("test_operation")
    time.sleep(0.1)  # 0.1ì´ˆ ëŒ€ê¸°
    duration = performance_monitor.end_timer(timer_id)
    performance_monitor.record_metric("test_operation", duration)

    stats = performance_monitor.get_stats("test_operation")
    print(f"ì„±ëŠ¥ í†µê³„: {stats}")

    print("âœ… ì„±ëŠ¥ ìµœì í™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")